{"hash":"09ee707e409a9f8e46b00410ac00ee920cb7c038","data":{"session":{"speaker":"Caleb Crandall","speaker2":"","bio":"Caleb is a software engineer in test at Beckman Coulter Life Sciences with over 10 years of experience, first as a developer who did a lot of testing and now as a dedicated tester. Working in a group that writes software for lab automation robots, he enjoys getting his hands dirty running hardware out in the development lab, and still keeps a pile of broken hardware \"trophies\" on his desk. Caleb is also a champion for context-driven testing and for software testing as a skilled profession.","bio2":"","title":"Testing Between the Buckets","abstract":"It's hard to read any kind of testing literature without seeing a laundry list of buzzwords for how to \"bucket\" the kinds of testing you do. Whether it's UI vs. API, white box vs. black box, happy path, \"manual\" vs. automated, the testing field seems to fall squarely in the first group in the classic quip, \"There are two kinds of people in the world: those who divide everything into two or more groups, and those that don't.\" However, when we overfocus on categorizing and bucketing our testing efforts, we risk missing critical bugs that don't cooperate with our neat categorization of testing efforts. Thinking outside the box (or bucket!) can generate test ideas that don't neatly fit into commonly-defined test types--and that's a good thing. In this talk, I provide some practical examples from my own experience of finding problems \"between the buckets\" and encourage you to unbucket your test activities to do the same. You might come up with some interesting ideas of your own by considering how to combine ideas from traditionally separate buckets.","time":"12:45 - 1:45","room":"Student Alumni Room","linkedin":"https://www.linkedin.com/in/caleb-crandall-a02478bb/","twitter":"","website":"","linkedin2":"","twitter2":"","website2":"","youtube":"","youtube2":""}},"context":{}}