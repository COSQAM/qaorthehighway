{"hash":"295597b73e0fc14524b608d9b6d9bbb27738cbc6","data":{"session1":{"edges":[{"node":{"speaker":"Joe Colantonio","speaker2":"","title":"Actionable Automation Awesomeness in Testing","abstract":"Get ready to supercharge your testing game with Actionable Automation Awesomeness!\n\nWondering how to take your automation skills to the next level? Look no further! As the host of Test Guild Automation podcast, I have interviewed over 500 top-notch test engineers in the industry, and I'm excited to share what I've learned with you.\n\nFrom the most common themes to the best practices, I'll reveal the secrets to success with automation awesomeness. And the best part? I'll show you how it relates to hobby farming (because who doesn't love cute animal pics!).\n\nDon't miss out on the opportunity to apply my guests' insights and my own automation experiences to your own test automation projects. Get actionable advice that you can start using right away to achieve testing excellence. Are you ready to take your testing skills to the next level? Let's do this!","time":"8:00 - 9:00","room":"East Ballroom"}}]},"session2":{"edges":[]},"session3":{"edges":[]},"session4":{"edges":[]},"session5":{"edges":[]},"session6":{"edges":[]},"session7":{"edges":[{"node":{"speaker":"Raj Subrameyer","speaker2":"","title":"** Session Title Coming **","abstract":"** We'll be posting the session abstract shortly. Please check back later **","time":"4:15 - 5:15","room":"East Ballroom"}},{"node":{"speaker":"Damian Synadinos","speaker2":"","title":"Word Smatter","abstract":"\"Testers [do|don’t] (help) [prevent|detect] problems.\"\n\nThroughout my career, I’ve encountered numerous variations of this phrase and discussed the underlying ideas often. The phrase uses just a few, small words to express many, big ideas. And so, it is valuable and critical to understand what each word means individually in order to better understand the ideas they convey collectively.\n\nSemantics is the study of meaning in words. The session begins with a brief and broad overview of semantics and related ideas. This sets the stage for deep analysis of each individual word in the phrase above and its potential meaning. We collaboratively consider:\n\nTesters – What might this word mean to different people and in different contexts?\n\nDo/Don’t – What do normative and descriptive statements have to do with it?\n\nHelp – How does the inclusion/exclusion of this word affect the meaning of the phrase?\n\nPrevent/Detect – What does causality and relativism have to do with which word we choose?\n\nProblems – What exactly is the thing that is being prevented or detected?\n\nThis session demystifies and promotes semantics, and goes beyond wordplay to introduce critical concepts that have practical impacts on testers, their roles, and their responsibilities.","time":"4:15 - 5:15","room":"East Ballroom"}},{"node":{"speaker":"Andrew Knight","speaker2":"","title":"Managing the Test Data Nightmare","abstract":"Good data for testing can be a nightmare to manage. Sometimes, teams don’t have much control over the data in their systems under test—it’s just dropped in, and it can change arbitrarily. Other times, teams need to build their own data sets, either before testing or during testing. Inaccurate data can leave test gaps. Incorrect or stale data can break tests. Large data can consume too much time. Ugh!\n\nIn this talk, we’ll cover strategies for defeating many types of test data nightmares:\n\n* recognizing the difference between product data and test case data\n* deciding when to prepare data statically beforehand or dynamically during testing\n* using data to control how tests run or reflect product state\n* hard-coding values versus discovering data in the system\n* avoiding collisions on shared data\n\nThe strategies we cover can be applied to any project in any language, especially Django. After this talk, you will wake up from the nightmare and handle test data cleanly and efficiently like a pro!","time":"4:15 - 5:15","room":"East Ballroom"}},{"node":{"speaker":"Melissa Tondi","speaker2":"","title":"Automation - We're Doing it Wrong","abstract":"The term automation as it pertains to software testing has been a driving force in defining the software testing industry. For many years, we've used it as a catch-all to determine whether a tester, testing team, or IT organization is successful. In this talk, we will discuss the five misconceptions that are pervasive within companies - including using a percentage or number of test cases to define success and specifying a title/role for those who automate and matrixing that role across teams versus embedding it within the project they are supporting. Melissa will discuss re-booting our current thinking of automation and show tactics to address the five misconceptions that have contributed to what many of us would consider one of the wedges that divide the testing industry. In addition, she will share practical and proven approaches you can take back with you to show immediate and valuable results.","time":"4:15 - 5:15","room":"East Ballroom"}},{"node":{"speaker":"Jordan Powell","speaker2":"","title":"API Testing Made Easy","abstract":"API's are a vital part of how we build applications today. It's how we send data from point A to Point B. They are sort of like the planes, trains and automobiles of the digital world.\n\nThough they are a key piece to building applications, they aren't always easy to test. In this talk, I will show you how easy it is to write API tests using Cypress.","time":"4:15 - 5:15","room":"East Ballroom"}},{"node":{"speaker":"Matthew Eakin","speaker2":"","title":"Test Strategy: The Best Friend You Never Knew","abstract":"Companies often get caught in a costly cycle. They rush to get a testing tool in place because it will “solve most of their manual testing problems.” Then spend a hard 6-12 months implementing a solution which isn’t quite fitting their needs. And it’s not doing everything the salesman said it could. As the time to renew licenses approaches your faced with a hard decision: replace this tool with another (potentially repeating the difficult implementation process for a second time next year) OR grind it out and adjust your processes to make the tool fit. Neither path is a good one.\n\nA more important question to ask is “How did you get yourself into this difficult position to begin with?” As I talk to more and more organizations in this difficult position, I see a pattern emerging. None of them have an over-arching Test Strategy in place. The tool they chose isn’t solving “most of their manual testing problems” because they have not taken the time to thoroughly identify what all those problems are, they have not taken the time to thoroughly identify where they think they want to be in 2 or 5 years, and they have not taken the time to think through how Tool A or B can help them through their journey from current to future state.\n\nA well put-together Test Strategy can help you guide these treacherous waters. In this presentation Mr. Eakin will walk your through the 5 W’s of testing: What? Where? When? Who? And HoW? What tests are needed in your full tech stack? Where (which environments) will these test be executed in? When will these tests be executed? Who will create, monitor and maintain the tests? After you have asked and answered the first 4 W’s, you are now ready to ask and answer the last: hoW (using which tools) will these tests be executed?\n\nWith a Test Strategy in hand, you will be ready to overcome any obstacle thrown at your team and do it without missing a beat. It will become your best friend.","time":"4:15 - 5:15","room":"East Ballroom"}},{"node":{"speaker":"Leandro Melendez","speaker2":"","title":"Chihuahua load tests!","abstract":"Because, bigger isn't always better. Especially nowadays.\n\nDo your teams need help accommodating those humongous load tests in your agile & continuous projects?\nDo you need frozen environments? Or, stop (freeze) all new changes until you can execute your colossal test? Everything to find the limits of your cloud, elastic, and distributed application?\nAll of that struggle to repeat it because the metrics you've got became invalid with the next release?\nYou should reframe the perspective and stop focusing on generating a few massive load tests. Why not have Chihuahua-sized load tests?\nYou can have a lot of those! They are small, cute, and pretty fast. You can even carry them around with you!\n\nThe list of advantages goes on and on. In this session, Leandro will describe the advantages of these tiny and cute load tests, the reasons to stop focusing on St. Bernard-sized load tests, and some tips on how to get the most out of Chihuahua-sized load tests.","time":"4:15 - 5:15","room":"East Ballroom"}},{"node":{"speaker":"Jeff Sing","speaker2":"","title":"Establishing your Quality Roadmap through Quarterly Service Delivery Reviews","abstract":"Do you ever feel in your role as a QA leader or Testing Engineer that you get assigned tasks that seem more like stop gaps than actual work that will drive lasting quality improvement? Does it ever feel challenging to get other engineering leaders to align on what projects will be more impactful, rather than reacting to what’s currently blocking them? Do you find it hard to express what quality really looks to your senior leadership team?\n\nWhile running Quality Engineering Programs, I often had these challenges in determining what work we should be delivering. One of the tools I utilized to help navigate and establish direction was running a Quality Service Delivery Review which helped establish:\n- What does healthy quality look like in your engineering organization (code quality, engineering process, deliverables?)\n- Is the Quality Organization successful in delivering this (what KPI’s and how is this consumed)?\n- Is our overall engineering output actually delivering with quality (what happens if it’s not)?\n\nAre our customers satisfied with our product and how can we determine this?\n\nBeing able to answer the questions above will allow you to align with the engineering leadership team on what quality initiatives should be worked on quarter to quarter.\n\nMy talk will focus on the following:\n- The case for utilizing a feedback mechanism like the Quality Service Delivery Review\n- What kind of content, metrics, and data should you be preparing and sharing\n- How to drive engagement with the participants in your Service Delivery Review\n- Utilizing the above to create alignment to build out your roadmap for execution","time":"4:15 - 5:15","room":"East Ballroom"}}]}},"context":{}}